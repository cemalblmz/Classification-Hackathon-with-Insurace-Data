# -*- coding: utf-8 -*-
"""Classification Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UQ64mk04l2qs0olhFNPXc9yzSZ27ba4q

## Araç Sigortası Satış Tahmin Problemi
Araç sahiplerinin araç sigortası satın almak konusundaki niyetlerinin tespiti sigorta şirketleri için büyük önem taşır. Doğru tahminler sigorta şirketleri için bir iletişim stratejisi planlayarak potansiyel müşterilere ulaşma, iş modellerini ve gelirlerini optmize etme fırsatı yaratır.   

Müşterilerine sağlık sigortası sağlayan bir sigorta şirketi bir önceki yılın poliçe sahiplerine araç sigortası satmayı planlamaktadır. Müşterilerin araç sigortası ile ilgilenip ilgilenmediklerini tahmin amacıyla kullanılacak şirket verisi müşterinin demografik bilgilerini (yaş, cinsiyet, bulunduğu il vb), araç özelliklerini (yaş ve hasar durumu) ve poliçe bilgilerini (prim ve kanal bilgileri) içermektedir. 

Aşağıdaki tablo veri setinde kullanılan öznitelikleri (features) ve açıklamalarını içermektedir.

|Öznitelik|Açıklama|
|---------|--------|
|Musteri_no|Anonim müşteri no|
|Cinsiyet|Müşteri cinsiyeti (E/K)|
|Yas|Müşteri doğum yılı|
|Ehliyet|Müşteri ehliyet durumu (Var/Yok)|
|Sehir|Müşterinin bulunduğu il|
|Gecmis_police|Müşterinin halihazırda araç sigortası var mı? (Var/Yok)|
|Arac_yasi|Aracın yaşı (<1 Yıl, 1-2 Yıl, 2-5 Yıl, 5-10 Yıl, >10 Yıl)|
|Hasar_durumu|Müşteri aracında geçmişte hasar oluştu mu? (E/H)|
|Yillik_prm|Yıllık prim bedeli|
|Acenta_no|Satış sorumlusu kod numarası (anonim)|
|Sure|Sigortalı (sağlık sigortası) olma süresi (gün)|
|Sonuc|Müşteri isteği (hedef): ilgileniyor (1), ilgilenmiyor (0)|

### Veri dosyaları
**1. `Arac_train.xlsx`** (254687 gözlem, 11 öznitelik, 1 hedef) : En iyi modelinizi seçmek için kullanacağınız eğitim verisi.

**2. `Arac_test.xlsx`** (63672 gözlem, 11 öznitelik) 

### Başarı metriği
Bu hackathon için değerlendirme metriğiniz "**ROC_AUC Score**" olarak belirlenmiştir.

### Hackathon rehberi
* DA503 finali için almış olduğunuz Kaggle hesaplarını burada kullanabilirsiniz. Önemli olan Public Leaderboard üzerinde isimlerinizin görünüyor olmasıdır.
* Kaggle'a giriş yaptıktan sonra **https://www.kaggle.com/t/96ff603c76bb404589d4e4d5c0068be4** linki üzerinden yarışma sayfasını açın.
* En iyi çalışan modeli elde ettiğinizde bir tahmin dosyası hazırlayın (örneğin **`pred.csv`** gibi) ve Kaggle'a yükleyin. Kullandığınız dosya isminin bir önemi bulunmamaktadır. Ancak bir hata ile karşılaşmamak için dosya formatı kritik öneme sahiptir (bir sonraki maddeyi lütfen dikkatle inceleyin).
* Unutmayın, Hackathon süresince **7** kez çözüm dosyası yükleme hakkınız bulunmaktadır. 

### Kaggle'a yüklenecek dosyayı nasıl hazırlayacağım?

Test verisini kullanarak oluşturduğunuz tahminlerinizi bir **.csv** dosyasına (örneğin **`pred.csv`**) birer satır olarak alt alta yazarak Kaggle'a yüklemeniz gerekmektedir. Dosyanızın aşağıdaki gibi bir formatta hazırlanmış olması bir hata ile karşılaşmamanız için oldukça önemlidir. Aşağıdaki örnekte "Prediction" kolonundaki değerler rasgele seçilmiştir.

Tahminlerimizi **dfpred** isimli bir dataframe'de topladığımızı düşünelim: 

<pre>
>>> dfpred.head(63672)
</pre>
|ID|Prediction|
|-----|--------|
|1|0|
|2|1|
|...|...|
|63671|0|
|63672|1|

Dosyada "ID" ve "Prediction" bir "header" olarak bulunmalıdır. "ID" kolonu 1 ile 63672 (her ikisi de dahil)
arasında değişen bir integer olarak verilmelidir.


### Kaggle tahmin dosyanızı nasıl değerlendiriyor?

Tahminlerinizi (pred.csv) Kaggle'a 7 kez yükleme hakkınız bulunmaktadır. Çözüm için kullandığınız modellerin hiç görmediği test verisi üzerindeki **ROC_AUC** performanslarını ancak bu şekilde ölçebilirsiniz. Modelde yapılan değişikliklerin sonuçlarını Kaggle üzerindeki performansınızı takip ederek yorumlayabilirsiniz. Aynı zamanda diğer grupların performansları ve sıralamaları da buradan görünür olacaktır.

**Dikkat**: Kaggle'da **Public Leaderboard** altında görünen (ROC_AUC) skorunuz test verisinin yalnızca %40'ı üzerindeki değerlendirme ile sıralamaya alınmaktadır. Hackathon'un nihai sıralaması ancak yarışma tamamlandığında test verisinin geriye kalan %60'ının da değerlendirmeye eklenmesiye (bu kısım sizlere görünür olmayan **Private Leaderboard** altında tutuluyor) ortaya çıkacaktır.
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import sklearn.preprocessing as pre
import sklearn.linear_model as lin
import sklearn.model_selection as mod
import sklearn.metrics as met
import sklearn.pipeline as pip
import sklearn.tree as tree
import sklearn.ensemble as ens
import seaborn as sns
from sklearn import cluster as clu
import sklearn.compose as cmp
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from imblearn import over_sampling as ove
from imblearn import under_sampling as und
from imblearn import combine as com
from imblearn import pipeline as imbPipe
from lightgbm import LGBMClassifier
from scipy import stats

"""# Basic Analysis"""

df = pd.read_excel("Arac_train.xlsx")
df.head()

pd.concat([df.describe(include="all").T,(round(100*(df.isnull().sum()/len(df.index)), 2)).rename('missing_ratio')], axis=1)

#No need for missing imputation

positive_ratio    = (str(round(df[df["Sonuc"] == 1]["Sonuc"].count()/df["Sonuc"].count(),2)*100))
negative_ratio = (str(round(df[df["Sonuc"] == 0]["Sonuc"].count()/df["Sonuc"].count(),2)*100))
sns.set_style("white")
sns.countplot(x='Sonuc', data=df, palette="Set1")
plt.title("positive_ratio: "+ positive_ratio + " - negative_ratio: " + negative_ratio )
plt.show()

"""The data is imbalanced. It requires Stratified Kfold."""

c_list = ["Cinsiyet","Ehliyet","Sehir","Arac_yasi","Gecmis_police","Hasar_durumu"]
p_values = []
test_stats = []
results= []
for i in c_list:
    cr_tab = pd.crosstab(df["Sonuc"],df[i])
    chi2, p , ddof, exp = stats.chi2_contingency(cr_tab, correction= False)
    if p < 0.025:
        #rint("Reject H0. JobSatisfaction and", i , "are NOT independent")
        result="NOT independent"
    else:
        #rint("Fail to Reject H0. JobSatisfaction and", i , "are independent")
        result="independent"
    msg = "Test Statistic: {}\np-value: {}\nDegrees of Freedom: {}"
    p_values.append(p)
    test_stats.append(chi2)
    results.append(result)
    
chi_test = pd.DataFrame({ "column_name":c_list ,"p_val" :p_values , "test stats" :test_stats , "results" : results})
chi_test

"""Based on findings from chi squared,It seems that all categorical features have some explanatory power on "sonuc""""

n_list = ["Yas","Yillik_prim","Acenta_no","Sure","Sonuc"]
sns.heatmap(df[["Yas","Yillik_prim","Acenta_no","Sure","Sonuc"]].corr(),cmap="seismic")
plt.show()
sns.heatmap(df[["Yas","Yillik_prim","Acenta_no","Sure","Sonuc"]].corr(method='spearman'),cmap="seismic")
plt.show()

"""#It seems acenta_no and Yas have some strong relationship."""

df[["Yas","Yillik_prim","Acenta_no","Sure","Sonuc"]].corr(method='spearman')

l = c_list+["Yas"]
for i in l :
    table=pd.crosstab(df[i], df.Sonuc)
    table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', figsize=(11,4), stacked=True,color=['teal','orangered','lightcoral'])
    plt.show()

"""1- Males has more positive ratio. Gender seems to have explanatory power,

2- People who have license have more positive ratio. I am planning to use for map function for these colums.

3- Sehir column is a good seperator. However it has too much category. Categories can be combined and a new column such as "Bolge"

4- Eastern Cities have more positive ratio. Bolge seems to be a fair variable.

5- As we expect, people who has insurace, do not have any positive value. 

6- People who had accident in the past seems to be more cautious

7- Old and young people seems to have less positive ratio. It seems fair considering they drive less. If I have time, I will try to make a new categoric feature which specifies old, young and middle age

# Feature Generation
"""

df["Yıl"] = 2021
df["Yas_new"] = df["Yıl"] - df["Yas"]
df.drop(columns=["Yıl"],inplace=True)
df.head()

def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df["bolge"] = df["Sehir"].apply(lambda x : bolge(x))
df["bolge"].value_counts()
table=pd.crosstab(df.bolge, df.Sonuc)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', figsize=(11,4), stacked=True,color=['teal','orangered','lightcoral'])
plt.show()

# It doesnt seem okay but I will keep it for now.

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df["Yas_c"] = df["Yas"].apply(lambda x : ynew(x))
df["Yas_c"].value_counts()
table=pd.crosstab(df.Yas_c, df.Sonuc)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', figsize=(11,4), stacked=True,color=['teal','orangered','lightcoral'])
plt.show()

# seems quite fine. I will keep it.

pd.DataFrame(df.Acenta_no.value_counts())[df.Acenta_no.value_counts() < 1000 ] # I will filter acenta_no and decrease categories to 15

pd.DataFrame(df.Acenta_no.value_counts())[df.Acenta_no.value_counts() < 1000 ].sum()

ac_list = list(pd.DataFrame(df.Acenta_no.value_counts())[df.Acenta_no.value_counts() > 1000 ].Acenta_no.index)

ac_list

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df["Acenta_new"] = df["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df["Acenta_new"].value_counts()
table=pd.crosstab(df.Acenta_new, df.Sonuc)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', figsize=(11,4), stacked=True,color=['teal','orangered','lightcoral'])
plt.show()

# new acenta_no seems to be fine.

# Mapping arac yası

df["Arac_yasi"] = df["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})

pd.concat([df.describe(include="all").T,(round(100*(df.isnull().sum()/len(df.index)), 2)).rename('missing_ratio')], axis=1)

sns.heatmap(df.corr(),cmap="seismic")
plt.show()
sns.heatmap(df.corr(method='spearman'),cmap="seismic")
plt.show()

df.columns

"""# Modelling

I will try a model with new dataset (with new categoric features), and I will try one with original dataset. It will be spars after one hot encoding.
"""

train_df= df[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure','Sonuc', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
train_df

train_df2= df[['Cinsiyet', 'Yas', 'Ehliyet', 'Sehir', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Acenta_no', 'Sure','Sonuc']]
train_df2.head()

#Required Functions

import matplotlib.cbook
from sklearn.model_selection import learning_curve
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,
                        n_jobs=1, train_sizes=np.linspace(0.01, 1.0, 5),scoring="f1"):
    plt.figure(figsize=(10,6))
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,scoring=scoring)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, '-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, '-', color="g",
             label="Cross-validation score")

    plt.legend(loc="best")
    plt.grid("on")
    return plt

def ROC_plotter(y_train_,y_test_,X_train_,X_test_,estimator):
    plt.figure(figsize=(14,4))
    plt.subplot(121)
    fpr, tpr, tresholds = met.roc_curve(y_train_ , estimator.predict_proba(X_train_)[:,1])
    roc_auc = met.roc_auc_score(y_train_ , estimator.predict_proba(X_train_)[:,1])
    plt.plot(fpr, tpr, label='ROC-AUC = %0.2f' % roc_auc, color='darkorange', linestyle='dashdot', lw=2)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - Train ')
    plt.legend(loc="lower right")
    plt.subplot(122)
    fpr, tpr, tresholds = met.roc_curve(y_test_ , estimator.predict_proba(X_test_)[:,1] )
    roc_auc = met.roc_auc_score(y_test_ , estimator.predict_proba(X_test_)[:,1])
    plt.plot(fpr, tpr, label='ROC-AUC = %0.2f' % roc_auc, color='darkorange', linestyle='dashdot', lw=2)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - Test')
    plt.legend(loc="lower right")
    plt.show()

def PrecisionRecallCurve(y_train_,y_test_,X_train_,X_test_,estimator):
    plt.figure(figsize=(14,4))
    plt.subplot(121)
    plt.title("Precision vs Recall Training")
    precision, recall, tresholds = met.precision_recall_curve(y_train_,estimator.predict_proba(X_train_)[:,1])
    plt.plot(tresholds,precision[:-1],"--",color="navy",label="Precison: TP / (TP+FP)")
    plt.plot(tresholds,recall[:-1],"--",color="darkorange",label='Recall: TP / (TP+FN)')
    plt.legend()
    plt.subplot(122)
    plt.title("Precision vs Recall Test")
    precision, recall, tresholds = met.precision_recall_curve(y_test_,estimator.predict_proba(X_test_)[:,1])
    plt.plot(tresholds,precision[:-1],"--",color="navy",label="Precison: TP / (TP+FP)")
    plt.plot(tresholds,recall[:-1],"--",color="darkorange",label='Recall: TP / (TP+FN)')
    plt.legend()
    plt.show()
    
def PrecisionRecallCurve2(y_train_,y_test_,X_train_,X_test_,estimator):
    plt.figure(figsize=(14,4))
    plt.subplot(121)
    plt.title("Precision vs Recall Training")
    precision, recall, tresholds = met.precision_recall_curve(y_train_,estimator.predict_proba(X_train_)[:,1])
    pr_auc = met.auc(recall, precision)
    plt.plot(recall,precision,"--",color="darkorange",label='LR (PR-AUC = %0.2f)' % pr_auc)
    no_skill = len(y_train_[y_train_==1]) / len(y_train_)
    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='navy', label='No Skill')
    plt.legend()
    plt.xlabel("precision")
    plt.ylabel("recall")
    plt.title("precision recall curve")
    plt.subplot(122)
    plt.title("Precision vs Recall Test")
    precision, recall, tresholds = met.precision_recall_curve(y_test_,estimator.predict_proba(X_test_)[:,1])
    pr_auc = met.auc(recall, precision)
    plt.plot(recall,precision,"--",color="darkorange",label='LR (PR-AUC = %0.2f)' % pr_auc)
    no_skill = len(y_test[y_test==1]) / len(y_test)
    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='navy', label='No Skill')
    plt.legend()
    plt.xlabel("precision")
    plt.ylabel("recall")
    plt.show()

"""# Random Forest with  dataset1"""

train_df.head(2)

y = train_df["Sonuc"]
X = train_df.drop(columns=["Sonuc"])

X_train, X_test, y_train, y_test = mod.train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)

import warnings
warnings.filterwarnings('ignore') 


c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', ens.RandomForestClassifier(random_state=42))
                              ])
params = {
    'clf__criterion': ['gini']   ,   #['entropy', 'gini'], I have tried commented parameters and narrow the search
    'clf__max_features': [7]  ,  # [3,5,7],
    'clf__max_depth': [10]   ,       #[4,7,10],
    'clf__min_samples_leaf': [1],    #[1, 3],
    'clf__min_samples_split': [3],    #[1, 3],
    'clf__class_weight':[None]}      #["balanced",None]

kfold = mod.StratifiedKFold(n_splits=3)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

"""AUC scores are quite close in training and test data. There is no sign of overfitting. However, performance in predicting positive class is not okay. Recall is too low. This may be related with default treshold 0.5. AUC score ignores model performance in positive class. I will check learning curves if there is any over/underfitting sign. I will also make a gridsearch to maximize f1 score to check if I can build a betrter model which can predickt positive class without lowering the AUC Score

"""

title = 'Learning Curves for RF'
kfold = mod.StratifiedKFold(n_splits=2, shuffle=True, random_state=42)
plot_learning_curve(grid.best_estimator_, title, X_train, y_train, cv=kfold,scoring='roc_auc')
plt.show()

#First upload

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()

df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})

df_test.head(2)

test_df= df_test[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
test_df.head(2)

pred_prob1 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob1.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. BU NOKTADA COK SURE KAYBETTIGIM ICIN FAZLA DENEME  YAPAMADIM
pred.to_csv('pred.csv', index=False)

pred_prob1.reset_index().rename(columns={'index': 'ID'}).to_csv('pred.csv', index=False)

#pd.concat((df_test.index,pred_prob1),axis=1).rename(columns={'Musteri_no': 'ID'}).to_csv('pred.csv', index=False)

"""# RF Trial 2"""

import warnings
warnings.filterwarnings('ignore') 


c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', ens.RandomForestClassifier(random_state=42))
                              ])
params = {
    'clf__criterion': ['gini']   ,   #['entropy', 'gini'], I have tried commented parameters and narrow the search
    'clf__max_features': [7]  ,                # [3,5,7],
    'clf__max_depth': [10]   ,                 #[4,7,10],
    'clf__min_samples_leaf': [1],              #[1, 3],
    'clf__min_samples_split': [3],             #[1, 3],
    'clf__class_weight':["balanced"]}     #["balanced",None]

kfold = mod.StratifiedKFold(n_splits=3)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='f1',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

#AUC Scores are same but recall of positive class is quite better.

# 2'nd submission

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()
df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})
test_df= df_test[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
test_df.head()

pred_prob2 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob2.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. 
pred.to_csv('pred.csv', index=False)

"""# XGB 1"""

y = train_df["Sonuc"]
X = train_df.drop(columns=["Sonuc"])
X_train, X_test, y_train, y_test = mod.train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

lrList = [0.07,0.1, 0.3,0.5]
plt.figure(figsize=(15,12))
j = 0
for lr in lrList:
    j += 1 
    trn_loss = [] ; val_loss = []
    for nest in np.linspace(50,200,50, dtype=int):
        pipeline = pip.Pipeline(steps=[('preprocessor', preprocessor),
                           ('classifier',   XGBClassifier(n_estimators=nest, eval_metric='logloss',learning_rate=lr,verbosity = 0, verbose=0, n_jobs=-1))
                          ])
        pipeline.fit(X_train, y_train)
        trn_loss.append(met.log_loss(y_train, pipeline.predict_proba(X_train)))
        val_loss.append(met.log_loss(y_test, pipeline.predict_proba(X_test)))
    plt.subplot(2,3,j)
    plt.plot(np.linspace(50,200,50, dtype=int), trn_loss, '-r', label='training_loss')
    plt.plot(np.linspace(50,200,50, dtype=int), val_loss, '-b', label='val_loss')
    plt.title("Learning rate = {0}".format(lr))
    plt.ylabel('Error')
    plt.xlabel('num_components')
    plt.legend(loc='upper right')
plt.show()

#  learning rate 0.3 and n estimator 80 seems quite okay. Because of the training time, this combination seems to be fine.

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', XGBClassifier(eval_metric='logloss',verbosity = 0, verbose=0, n_jobs=-1,random_state=42))
                              ])
params = { 
              'clf__learning_rate'    : [0.3],
              'clf__n_estimators'     : [80],
              'clf__max_depth'        : [8,10],#[4,6,8,10]
              'clf__min_child_weight' : [50],  # [30,50,150]
              'clf__gamma'            : [1,5], # [1,5,10,50]
              #'clf__subsample'       : [ 0.9, 1],
              #'clf__colsample_bytree': [ 0.9, 1],
              #'clf__reg_alpha'        : [ 1, 3],
              #'clf__reg_lambda'       : [ 2, 3]
              #'clf__class_pos_weigh' : [1, 10, 25, 50, 75, 99, 100, 1000,    
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[0]),
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[1])]
              #'clf__early_stopping_rounds' : [10]
            }

kfold = mod.StratifiedKFold(n_splits=2)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

# Not much improvement on RF Model. However it performed on unseen test data on kaggle. 
# I will make one more trial.

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()
df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})
test_df= df_test[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
test_df.head()
pred_prob3 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob3.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. 
pred.to_csv('pred.csv', index=False)

"""# XGB Second Trial"""

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', XGBClassifier(eval_metric='logloss',verbosity = 0, verbose=0, n_jobs=-1,random_state=42))
                              ])
params = { 
              'clf__learning_rate'    : [0.3],
              'clf__n_estimators'     : [80],
              'clf__max_depth'        : [6,8],
              'clf__min_child_weight' : [10,20,30], # [30,50,150]
              'clf__gamma'            : [3,5,9], # [1,5,10,50]
              #'clf__subsample'       : [ 0.9, 1],
              #'clf__colsample_bytree': [ 0.9, 1],
              #'clf__reg_alpha'        : [ 1, 3],
              #'clf__reg_lambda'       : [ 2, 3]
              #'clf__class_pos_weigh' : [1, 10, 25, 50, 75, 99, 100, 1000,    
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[0]),
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[1])]
              #'clf__early_stopping_rounds' : [10]
            }

kfold = mod.StratifiedKFold(n_splits=2)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

# very small improvement in cv score
# kaggle score also improved. 
# I will keep lowering regularization parameters.

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()
df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})
test_df= df_test[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
test_df.head()
pred_prob4 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob4.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. 
pred.to_csv('pred.csv', index=False)

"""# XGB Third Trial - Selected Model"""

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', XGBClassifier(eval_metric='logloss',verbosity = 0, verbose=0, n_jobs=-1,random_state=42))
                              ])
params = { 
              'clf__learning_rate'    : [0.3],
              'clf__n_estimators'     : [80],
              'clf__max_depth'        : [6,8],
              'clf__min_child_weight' : [5,10], # [30,50,150]
              'clf__gamma'            : [5,8,11], # [1,5,10,50]
              #'clf__subsample'       : [ 0.9, 1],
              #'clf__colsample_bytree': [ 0.9, 1],
              'clf__reg_alpha'        : [ 1],
              'clf__reg_lambda'       : [ 1]
              #'clf__class_pos_weigh' : [1, 10, 25, 50, 75, 99, 100, 1000,    
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[0]),
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[1])]
              #'clf__early_stopping_rounds' : [10]
            }

kfold = mod.StratifiedKFold(n_splits=3)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

title = 'Learning Curves for RF'
kfold = mod.StratifiedKFold(n_splits=2, shuffle=True, random_state=42)
plot_learning_curve(grid.best_estimator_, title, X_train, y_train, cv=kfold,scoring='roc_auc')
plt.show()

# very little improvement again. I will make one more xgboost submission.

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()
df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})
test_df= df_test[['Cinsiyet', 'Ehliyet', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Sure', 'Yas_new', 'bolge', 'Yas_c', 'Acenta_new']]
test_df.head()
pred_prob5 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob5.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. 
pred.to_csv('pred.csv', index=False)

"""# XGB Trial 4"""

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','bolge','Yas_c','Acenta_new']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(drop='first'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', XGBClassifier(eval_metric='logloss',verbosity = 0, verbose=0, n_jobs=-1,random_state=42))
                              ])
params = { 
              'clf__learning_rate'    : [0.3],
              'clf__n_estimators'     : [80],
              'clf__max_depth'        : [4,6,8],
              'clf__min_child_weight' : [3,5], # [30,50,150]
              'clf__gamma'            : [5,8], # [1,5,10,50]
              #'clf__subsample'       : [ 0.9, 1],
              #'clf__colsample_bytree': [ 0.9, 1],
              'clf__reg_alpha'        : [ 1,2],
              'clf__reg_lambda'       : [ 1,2]
              #'clf__class_pos_weigh' : [1, 10, 25, 50, 75, 99, 100, 1000,    
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[0]),
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[1])]
              #'clf__early_stopping_rounds' : [10]
            }

kfold = mod.StratifiedKFold(n_splits=2)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

"""# XGB Trial with original sparse(after encoding) TrainSet - Best Private Performance"""

#df[['Cinsiyet', 'Yas', 'Ehliyet', 'Sehir', 'Gecmis_police','Arac_yasi', 'Hasar_durumu', 'Yillik_prim', 'Acenta_no', 'Sure','Sonuc']]
train_df2.head()

y = train_df2["Sonuc"]
X = train_df2.drop(columns=["Sonuc"])
X_train, X_test, y_train, y_test = mod.train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)

c = ['Cinsiyet', 'Ehliyet', 'Gecmis_police', 'Hasar_durumu','Sehir','Acenta_no']

categoricTransformer = pip.Pipeline(steps=[("encoder",pre.OneHotEncoder(handle_unknown='ignore'))
                                         ])

preprocessor = cmp.ColumnTransformer([("nm",categoricTransformer,c)], remainder='passthrough')

pipeline = pip.Pipeline(steps=[ ('prep',preprocessor),
                                ('clf', XGBClassifier(eval_metric='logloss',verbosity = 0, verbose=0, n_jobs=-1,random_state=42))
                              ])
params = { 
              'clf__learning_rate'    : [0.3],
              'clf__n_estimators'     : [80],
              'clf__max_depth'        : [6,8],
              'clf__min_child_weight' : [3], # [30,50,150]
              'clf__gamma'            : [5], # [1,5,10,50]
              #'clf__subsample'       : [ 0.9, 1],
              #'clf__colsample_bytree': [ 0.9, 1],
              #'clf__reg_alpha'        : [ 1,2],
              #'clf__reg_lambda'       : [ 1,2]
              #'clf__class_pos_weigh' : [1, 10, 25, 50, 75, 99, 100, 1000,    
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[0]),
              #                      round(((y_train.value_counts().values / y_train.shape[0] ) * 100)[1])]
              #'clf__early_stopping_rounds' : [10]
            }

kfold = mod.StratifiedKFold(n_splits=2)
grid  = mod.GridSearchCV(estimator=pipeline, param_grid=params, cv=kfold, scoring='roc_auc',verbose=1,n_jobs=-1)
grid.fit(X_train,y_train)
print(); print("Best CV score: %f using %s\n" % (grid.best_score_, grid.best_params_))
print("Training")
print(met.classification_report(y_train, grid.predict(X_train)))
print("Test")
print(met.classification_report(y_test, grid.predict(X_test)))
ROC_plotter(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve(y_train,y_test,X_train,X_test,grid.best_estimator_)
PrecisionRecallCurve2(y_train,y_test,X_train,X_test,grid.best_estimator_)

# performed better on test data. However it performed worse than others on public board.

X_train.head(2).columns

df_test = pd.read_excel("Arac_test.xlsx")
df_test.head()
df_test["Yıl"] = 2021
df_test["Yas_new"] = df_test["Yıl"] - df_test["Yas"]
df.head()
def bolge(sehir):
    b1 = ["Adana","Antalya","Hatay","Isparta","Mersin","Osmaniye","Maras"]
    b2 = ["Erzurum","Malatya","Van","Agri","Elazig","Mus"]
    b3 = ["Denizli","Kutahya","Manisa","Mugla","Afyon","Aydin","Izmir","Usak"]
    b4 = ["Batman","Gaziantep","Mardin","Adiyaman","Diyarbakir","Sirnak","Urfa"]
    b5 = ["Aksaray","Ankara","Kayseri","Konya","Nigde","Sivas","Yozgat","Eskisehir"]
    b6 = ["Corum","Duzce","Giresun","Kastamonu","Ordu","Samsun","Tokat","Trabzon","Zonguldak"]
    b7 = ["Bursa","Canakkale","Edirne","Kocaeli","Sakarya","Tekirdag","Balikesir","Istanbul"]
    if sehir in b1:
        return "1"
    elif sehir in b2:
        return "2"
    elif sehir in b3:
        return "3"
    elif sehir in b4:
        return "4"
    elif sehir in b5:
        return "5"
    elif sehir in b6:
        return "6"
    elif sehir in b7:
        return "7"
    else:
        return "7"
df_test["bolge"] = df_test["Sehir"].apply(lambda x : bolge(x))

def ynew(y):
    if y >1992:
        return 1
    elif y <=1992 and y > 1958:
        return 2
    else:
        return 3
df_test["Yas_c"] = df_test["Yas"].apply(lambda x : ynew(x))

def acenta(ac_list,ac):
    if ac in ac_list:
        return ac
    else:
        return 999
df_test["Acenta_new"] = df_test["Acenta_no"].apply(lambda x : acenta(ac_list,x))
df_test["Acenta_new"].value_counts()
df_test["Arac_yasi"] = df_test["Arac_yasi"].map({'1-2 Yil':1, '< 1 Yil':0, '2-5 Yil':3, '5-10 Yil':4, '> 10 Yil':5})
test_df= df_test[['Cinsiyet', 'Yas', 'Ehliyet', 'Sehir', 'Gecmis_police', 'Arac_yasi','Hasar_durumu', 'Yillik_prim', 'Acenta_no', 'Sure']]
test_df.head()
pred_prob6 = pd.DataFrame(grid.best_estimator_.predict_proba(test_df)[:,1],columns=["Prediction"])
pred = pred_prob6.reset_index().rename(columns={'index': 'ID'})
pred["ID"] = pred["ID"] + 1 # index 0dan baslayınca hata verdi. 
pred.to_csv('pred.csv', index=False)

